# NoteBuddy Backend

AI-powered note generation backend that processes Chinese transcripts using DeepSeek LLM.

## Features

- **User Authentication**: JWT-based authentication system
- **Transcript Management**: CRUD operations for Chinese transcripts
- **AI-Powered Note Generation**: Convert Chinese transcripts to structured notes using DeepSeek
- **Follow-up Questions**: Generate relevant questions based on generated notes
- **Note Updating**: Incorporate answers to questions into existing notes
- **User-specific Data**: All data is isolated per user

## Technology Stack

- **Framework**: FastAPI (Python 3.11)
- **Database**: SQLite with SQLAlchemy
- **AI Integration**: DeepSeek API for Chinese language processing
- **Authentication**: JWT tokens
- **Virtual Environment**: Python 3.11 venv

## Project Structure

```
notebuddy-backend/
├── app/
│   ├── __init__.py
│   ├── main.py              # FastAPI application and endpoints
│   ├── models.py            # Database models (User, Transcript, Note)
│   ├── schemas.py           # Pydantic schemas for validation
│   ├── auth.py              # Authentication logic
│   ├── ai_services.py       # DeepSeek integration
│   └── crud.py              # Database operations
├── main.py                  # Application entry point
├── test_unit.py             # Unit tests
├── test_api.py              # API integration tests
├── requirements.txt         # Python dependencies
├── .env                     # Environment variables
└── notebuddy.db            # SQLite database
```

## API Endpoints

### Authentication
- `POST /auth/register` - Register new user
- `POST /auth/login` - Login and get JWT token

### Transcripts
- `POST /transcripts/` - Create new transcript
- `GET /transcripts/` - List user's transcripts
- `GET /transcripts/{id}` - Get specific transcript
- `PUT /transcripts/{id}` - Update transcript
- `DELETE /transcripts/{id}` - Delete transcript

### AI Features
- `POST /transcripts/{id}/generate-note` - Generate note from transcript
- `POST /notes/{id}/generate-questions` - Generate follow-up questions
- `POST /notes/{id}/update-with-answer` - Update note with answers

### Notes
- `GET /notes/` - List user's notes
- `GET /notes/{id}` - Get specific note
- `DELETE /notes/{id}` - Delete note

## Setup Instructions

1. **Clone and setup virtual environment**:
```bash
python3.11 -m venv venv
source venv/bin/activate
```

2. **Install dependencies**:
```bash
pip install -r requirements.txt
pip install email-validator requests
```

3. **Configure environment**:
Update `.env` file with your DeepSeek API key and secret key:
```
DEEPSEEK_API_KEY=your-deepseek-api-key
SECRET_KEY=your-secret-key-here-change-in-production
DATABASE_URL=sqlite+aiosqlite:///./notebuddy.db
```

4. **Run the application**:
```bash
python main.py
```

5. **Access API documentation**:
Open http://localhost:8000/docs in your browser

## Testing

### Unit Tests
Run unit tests (no server required):
```bash
python test_unit.py
```

### API Tests
Run API integration tests (server must be running):
```bash
python test_api.py
```

## Usage Example

1. **Register a user**:
```bash
curl -X POST "http://localhost:8000/auth/register" \
     -H "Content-Type: application/json" \
     -d '{"username": "testuser", "email": "test@example.com", "password": "password123"}'
```

2. **Login to get token**:
```bash
curl -X POST "http://localhost:8000/auth/login" \
     -H "Content-Type: application/json" \
     -d '{"username": "testuser", "password": "password123"}'
```

3. **Create a transcript** (use the token from login):
```bash
curl -X POST "http://localhost:8000/transcripts/" \
     -H "Authorization: Bearer YOUR_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{"title": "会议记录", "content": "今天会议讨论了项目进展...", "language": "zh"}'
```

4. **Generate a note from the transcript**:
```bash
curl -X POST "http://localhost:8000/transcripts/1/generate-note" \
     -H "Authorization: Bearer YOUR_TOKEN"
```

## Chinese Language Support

The backend is specifically optimized for Chinese language processing:
- Uses DeepSeek LLM which excels at Chinese text
- Proper handling of Chinese character encoding
- Chinese-specific prompt engineering for better results
- Support for long Chinese transcripts

## Security Features

- JWT token-based authentication
- Password hashing with salt
- User-specific data isolation
- Input validation with Pydantic schemas
- Environment variable protection for API keys

## Development

The backend includes:
- Comprehensive unit tests
- API documentation automatically generated by FastAPI
- Error handling and validation
- Async/await support for better performance
- CORS middleware for frontend integration

## Next Steps

For production deployment, consider:
- Using PostgreSQL instead of SQLite
- Adding rate limiting
- Implementing proper logging
- Adding monitoring and health checks
- Setting up proper SSL/TLS
- Using environment-specific configurations
